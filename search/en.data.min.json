[{"id":0,"href":"/documentation/post-renderers/built-in/","title":"Built-in","parent":"Post Renderers","content":"The following Post Renderers are built in and ship with the library.\n   Labels      "},{"id":1,"href":"/getting-started/concept/","title":"Concept","parent":"Getting Started","content":"Helmize is included as library chart. It just has all the function it needs to render the structure you give it and then returns the resulting contents. So it\u0026rsquo;s basically just a render engine.\nIn the below image we have the Releases (which are effecitively values which install your helm chart). In your helm chart you see different yamls organized in a structure which depends on input conditions eg. locations. Your chart includes a configuration filewhich defines these conditions and allows you to map it two values. Helmize will read the configuration and render inputs according to it.\nFor the Release Vanilla we see, that we have a configuration for the location which is east and a configuration for the env which is dev. On Install all files in the base/ folder are used, since these apply for all releases. For the location only the files in the location/east folder are considered. Same for the environment, only files in the environments/devfolder are considered. The release does not have a value for a customer but in the configuration we specified that the default value for customer is default. Therefor all files under customer/default are considered as well.\nFor the Release Customer A we see, that we have a value for the location which is west, a value for the env which is dev and prod and a value for customer which is A. On Install all files in the base/ folder are used, since these apply for all releases. For the location only the files in the location/west folder are considered. Same for the environment, only files in the environments/dev and environments/prod folder are considered. The customer is set to A therefor all files under customer/A are considered as well.\nFor both examples you might notice, that files with the same name are only present once in the resulting files. That\u0026rsquo;s because their content was merged. This way can just change eg. the version in the release.yaml without having to replicate the entire content and can adjust values on stage basis.\nThat\u0026rsquo;s it, See Quickstartfor an easy example how to setup helmize up.\n"},{"id":2,"href":"/documentation/configuration/","title":"Configuration","parent":"Documentation","content":"The configuration is the core component which defines how your deployment structure will be organized\nFile     By default the configuration is located in a helmize.yaml file within your charts root folder. You will get errors if the configuration file is missing, has wrong formatting or types.\nTemplating     The entire configuration file is templated. So you can also use sprig within the configuration file. You must make sure that after the templating the content resolves to valid YAML, otherwise the exection will fail.\nA simple example:\ninventory_directory: \u0026quot;structure/\u0026quot; conditions: {{- if $.Values.exclude_base }} - name: \u0026quot;base\u0026quot; path: \u0026quot;/base/\u0026quot; allow_root: true {{- end }} - name: \u0026quot;environment\u0026quot; key: {{ default \u0026quot;Values.env\u0026quot; $.Values.overwrite_env_key }} path: \u0026quot;env/\u0026quot; default: \u0026quot;test\u0026quot; When exclude_baseis set to false, the base condition won\u0026rsquo;t be used, since it\u0026rsquo;s not rendered in the configuration file:\nhelm template . --set exclude_base=false "},{"id":3,"href":"/documentation/structure/files/","title":"Files","parent":"Structure","content":"    Context     Within the Root context per File $ you can access the global Helm context, as usual.\nDropins     In Files you can access the data from Dropins via $.Data. So if you configured a dropin like this:\nhelmize.yaml\n... dropins: - patterns: [ \u0026#34;.*\u0026#34; ] data: elasticsearch: endpoint: \u0026#34;http://logging.company.com\u0026#34; port: 9200 You can access it in a file via:\nstructure/base/beat.yaml\n--- apiVersion: apps/v1 kind: DaemonSet metadata: name: filebeat namespace: kube-system labels: k8s-app: filebeat spec: selector: matchLabels: k8s-app: filebeat template: metadata: labels: k8s-app: filebeat spec: containers: - name: filebeat image: docker.elastic.co/beats/filebeat:8.0.0 env: - name: ELASTICSEARCH_HOST value: {{ $.Data.elasticsearch.endpoint }} - name: ELASTICSEARCH_PORT value: {{ $.Data.elasticsearch.port }} ... "},{"id":4,"href":"/documentation/configuration/general/","title":"General","parent":"Configuration","content":"Configuration     The following general configuration options are available in the helmize.yaml\nconditions     Required\nType slice\nRead more about conditionsdropins     Required\nType slice\nRead more about dropinsinventory_directory     Optional\nType string\nDefine a directory where the entire structure for helmize is located below. This path will be appended for all the condition\u0026rsquo;s paths.\ntemplates_directory     Optional\nType string\nDefine a directory where all templates for the dropins templates are located below. This path will be appended for all the templates in all dropinsforce     Optional\nType string Default false\nIf any file contains an error the template will fail. With force the template won\u0026rsquo;t fail even if there are errors. Files with errors will be skipped.\nfile_extensions     Optional\nType string/slice Default [ \u0026quot;yaml\u0026quot;, \u0026quot;yml\u0026quot;, \u0026quot;tpl\u0026quot; ]\nDefine which file extensions should be considered while looking through the directories. Just declare the extension without wildcard, this configuration does not accept regex pattern.\nfile_excludes     Optional\nType string/slice\nDefine which file names should be considered while looking through the directories. You can use regex patterns.\nmerge_strategy     Optional\nType string/slice Default path Valid Options file, path\nDefine how files are merged together.\nfile     Merge file content based on file name. If you have multiple files with the exact same name in one condition folder or over multiple folders, they are considered to be one final file and merged together.\nLet\u0026rsquo;s assume you have the following folder structure:\nstructure | +---stage/ | +---dev/ | release.yaml | subdir/release.yaml | ... | +---location/ | +---east/ | release.yaml | subdir/release.yaml | ... + All the files named release.yaml will be merged together and as output you will get a single release.yaml file.\npath     Merge file content based on file subpath. If you have multiple files with teh exact same name but different subpaths they will not be merged together.\nLet\u0026rsquo;s assume you have the following folder structure:\nstructure | +---stage/ | +---dev/ | release.yaml | subdir/release.yaml | ... | +---location/ | +---east/ | release.yaml | subdir/release.yaml | ... + The release.yaml files are merged together and the subdir/release.yaml are merged together.\n"},{"id":5,"href":"/getting-started/","title":"Getting Started","parent":"","content":"    Concept      Quickstart      Requirements     This documentation won\u0026rsquo;t explain the core concepts of Helmand Sprig templating, it is expected that you know these technologies.The only requirement for helmize is helm. The library was tested with the following helm version:\n v3.7.2  Limitations     Merge of files is done with the mergeOverwritefunction that comes with Sprig. You can\u0026rsquo;t combine any type of slice (lists). If you have two files with lists in a map, the prededing one will always overwrite the list contents. Therefor you must work around this with value templating when you want to combine values of lists.\n"},{"id":6,"href":"/documentation/post-renderers/built-in/labels/","title":"Labels","parent":"Built-in","content":"eow\n"},{"id":7,"href":"/guides/use/","title":"Use with","parent":"Guides","content":"Guides on how to integrate with different other tools.\n   Kustomization      "},{"id":8,"href":"/documentation/configuration/conditions/","title":"Conditions","parent":"Configuration","content":"Conditions translate into paths where files are looked up based on given values which are relevant for deployment. Conditions are declared as list, based on the order the files are looked up and merged.\nConfiguration     Each condition can have the followin configurations.\nname     Required\nType string\nUsed across helmize to reference to condition.\nkey     Optional\nType string\nPath to the value in the user delivered values which is used as key to lookup.\nkey_types     Optional\nType slice Default [ \u0026quot;string\u0026quot;, \u0026quot;slice\u0026quot; ]\nDefine the types the key must have. For example if you only want to allow a single value, the type should be slice. Types you can use are documented here:\n http://masterminds.github.io/sprig/reflection.html  required     Optional\nType boolean\nThe declared key must have a value. If no value is given the templating fails.\ndefault     Optional\nType string\nIf the declared key does not contain a value, this default value will be used.\npath     Optional\nType string\nThe path defines under which directory path the given values for the condition are looked up. If no path is given, the condition\u0026rsquo;s nameis used as path. Note that the path is complementary to the inventory_directoryfilter     Optional\nType string/slice\nFilter keylist for values that are not allowed and exclude them as valid path. The filter is executed against all inputs for this condition. If a filter matches a value, the value is removed. You can use regex patterns. The allow_rootis not affected by any filter and will always be added.\nreverse_filter     Optional\nType boolean\nReverses the filterconfiguration so that only values given with the filter are accepted.\nallow_root     Optional\nType boolean\nIn addition to checking all keys, it becomes also valid to have files directly in the root of the condition\u0026rsquo;s path.\n"},{"id":9,"href":"/documentation/structure/debug/","title":"Debug","parent":"Structure","content":"With large file structures it\u0026rsquo;s often difficult to understand, which files were merged or why content is missing.\nSummary     For such cases we have a summary which summarizes overything that happened during the helmize processing.\nTemplate     You can include the summary template, which returns the summary as YAML:\n{{- $summary := fromYaml (include \u0026quot;inventory.entrypoint.func.summary\u0026quot; $) -}} This way you could further process the output of helmize or eg. generate a good overview in the NOTES.txt of your chart.\nDeploy     When you have included the deploy template:\n{{- include \u0026quot;inventory.entrypoint.func.deploy\u0026quot; $ | nindent 0 -}} You can display the summary via values:\nhelm template . --set summary=true Reference     See all the fields which are returned in the summary\nReference ...  This is the summary output for the referencechart.\n## Contains all conditions conditions: # Each Condition returns the same fields, so here\u0026#39;s the reference for one ... # Condition Name - name: environment # Source configuration from configuration file config: default: test filter: - test - prod key: Values.env key_types: - string - slice name: environment path: env/ reverse_filter: true # Resulting Keys based on configuration  keys: - test # Resulting paths based on keys and root_path paths: - structure/env/test/ # Root path  root_path: env/ ## Errors # Any errors that were found during processing errors: [] ## Files # Contains all the files with extra information. Files are grouped based on the merge_strategy files: # Each file returns the same fields, so here\u0026#39;s the reference for one ... ## Checksum # SHA1 Checksum of the file\u0026#39;s content field - checksum: 180fcd1de54e143f1304991d9cf801262001f43287e78734e3b9e1e44dd694a0 ## Identifiert # Identifier for file, varies based on merge strategy identifier: podinfo/deploy.yaml ## Content # Content of all the files based on merge strategy  content: ... ## Dropins # Result of dropins which matched for this file dropins: ## Data # All data fields of matched dropins merged together  data: labels: custom.label: data registy.template: label ## Lookup # Which Template Files were looked up during dropin evaluation (useful when u are not explicit with your template paths) lookup: - tpls/registry.tpl ## Patterns # Which Dropin Patterns matched  patterns: - .* ## Templates # Templates which were successfully executed  templates: - tpls/registry.tpl ## Errors # Errors encountered during file merges (is given to parent errors field as well) errors: [] ## Files # All Files with their path (given from condition) which were considered files: - file: structure/base/podinfo/deploy.yaml path: structure/base/ - file: structure/env/test/podinfo/deploy.yaml path: structure/env/test/ ## Paths # All Files with their path (given from condition) which were considered for all files paths: - file: structure/base/podinfo/deploy.yaml path: structure/base/ - file: structure/base/podinfo/service.yaml path: structure/base/ - file: structure/env/test/podinfo/deploy.yaml path: structure/env/test/ - file: structure/env/test/podinfo/hpa.yaml path: structure/env/test/    "},{"id":10,"href":"/documentation/","title":"Documentation","parent":"","content":"    Configuration      General      Conditions      Dropins      Reference        Structure      Files      Debug      Templating        Post Renderers      Built-in      Labels        Extension        "},{"id":11,"href":"/documentation/post-renderers/extend/","title":"Extension","parent":"Post Renderers","content":"    "},{"id":12,"href":"/guides/use/kustomize/","title":"Kustomization","parent":"Use with","content":"Kustomize offers already a lot of post processing options through the kustomization file. We can simply use those capabilities.\n"},{"id":13,"href":"/getting-started/quickstart/","title":"Quickstart","parent":"Getting Started","content":"If you encounter any problems during the quickstart make sure to use the debug options. They help to understand what\u0026rsquo;s going on and what might be the problem.  First we create a new helm chart which is going to contain the entire deployment structure for helmize. We can simply do that with the following comment (In this case I will call the new chart reference, chose the name you would like):\nhelm create reference \u0026amp;\u0026amp; cd reference/ We can clear the templates/* content and the ǜalues.yaml, since we are going to recreate them.\nrm -rf templates/* \u0026amp;\u0026amp; rm -f values.yaml Now we add helmize as new chart dependency(Check out the release page or artifacthub to get the latest helmize version):\n# Chart.yaml ... dependencies: - name: helmize # Make sure to use a fixed version version: \u0026#34;\u0026gt;=0.0.0-0\u0026#34; repository: \u0026#34;https://buttahtoast.github.io/helm-charts/\u0026#34; ... Update dependencies to download the specified version for helmize:\nhelm dependency update Now we need to add a template which includes the entrypoint for helmize:\ncat \u0026lt;\u0026lt; EOF \u0026gt; ./templates/deploy.yaml {{- include \u0026#34;inventory.entrypoint.func.deploy\u0026#34; $ | nindent 0 }} EOF Now we create a very simplistic configuration in the chart root:\ncat \u0026lt;\u0026lt; EOF \u0026gt; ./helmize.yaml inventory_directory: \u0026#34;structure/\u0026#34; templates_directory: \u0026#34;tpls/\u0026#34; conditions: - name: \u0026#34;base\u0026#34; path: \u0026#34;/base/\u0026#34; allow_root: true EOF With this initial configuration we have added a base directory which will lookup all files within (it\u0026rsquo;s not reuired to have a base condition).\nStructure     Now we start creating our structure for the chart. We want to deploy podinfo(just the deployment) in the referenced base:\nmkdir -p structure/base/podinfo Under the structure we create some files so we can see the influence of helmize\nBase Files ...  Create Deployment file\ncat \u0026lt;\u0026lt; EOF \u0026gt; ./structure/base/podinfo/deploy.yaml apiVersion: apps/v1 kind: Deployment metadata: name: frontend spec: minReadySeconds: 3 revisionHistoryLimit: 5 progressDeadlineSeconds: 60 strategy: rollingUpdate: maxUnavailable: 0 type: RollingUpdate selector: matchLabels: app: frontend template: metadata: annotations: prometheus.io/scrape: \u0026#34;true\u0026#34; prometheus.io/port: \u0026#34;9797\u0026#34; labels: app: frontend spec: containers: - name: frontend image: ghcr.io/stefanprodan/podinfo:6.0.3 imagePullPolicy: IfNotPresent ports: - name: http containerPort: 9898 protocol: TCP - name: http-metrics containerPort: 9797 protocol: TCP - name: grpc containerPort: 9999 protocol: TCP command: - ./podinfo - --port=9898 - --port-metrics=9797 - --level=info - --backend-url=http://backend:9898/echo - --cache-server=cache:6379 env: - name: PODINFO_UI_COLOR value: \u0026#34;#34577c\u0026#34; livenessProbe: exec: command: - podcli - check - http - localhost:9898/healthz initialDelaySeconds: 5 timeoutSeconds: 5 readinessProbe: exec: command: - podcli - check - http - localhost:9898/readyz initialDelaySeconds: 5 timeoutSeconds: 5 resources: limits: cpu: 1000m memory: 128Mi requests: cpu: 100m memory: 32Mi EOF Create Service file\ncat \u0026lt;\u0026lt; EOF \u0026gt; ./structure/base/podinfo/service.yaml apiVersion: v1 kind: Service metadata: name: frontend spec: type: ClusterIP selector: app: frontend ports: - name: http port: 80 protocol: TCP targetPort: http EOF    After you have added those files and execute a template command:\nhelm template . The result should not be surprising, for now the two new added files are just rendererd with additional comments.\nTemplate Result ...  --- # Source: reference/templates/deploy.yaml # File: podinfo/service.yaml # Checksum 08b06c48a587e3fe6179875f70331bb97562a6e584dcb32807ce9eac7572fc8d apiVersion: v1 kind: Service metadata: name: frontend spec: ports: - name: http port: 80 protocol: TCP targetPort: http selector: app: frontend type: ClusterIP --- # Source: reference/templates/deploy.yaml # File: podinfo/deploy.yaml # Checksum 71f6b6d50be2ddace75a2259b577150467e85a80c2c29a10dd402446edb028b8 apiVersion: apps/v1 kind: Deployment metadata: name: frontend spec: minReadySeconds: 3 progressDeadlineSeconds: 60 revisionHistoryLimit: 5 selector: matchLabels: app: frontend strategy: rollingUpdate: maxUnavailable: 0 type: RollingUpdate template: metadata: annotations: prometheus.io/port: \u0026#34;9797\u0026#34; prometheus.io/scrape: \u0026#34;true\u0026#34; labels: app: frontend spec: containers: - command: - ./podinfo - --port=9898 - --port-metrics=9797 - --level=info - --backend-url=http://backend:9898/echo - --cache-server=cache:6379 env: - name: PODINFO_UI_COLOR value: \u0026#39;#34577c\u0026#39; image: ghcr.io/stefanprodan/podinfo:6.0.3 imagePullPolicy: IfNotPresent livenessProbe: exec: command: - podcli - check - http - localhost:9898/healthz initialDelaySeconds: 5 timeoutSeconds: 5 name: frontend ports: - containerPort: 9898 name: http protocol: TCP - containerPort: 9797 name: http-metrics protocol: TCP - containerPort: 9999 name: grpc protocol: TCP readinessProbe: exec: command: - podcli - check - http - localhost:9898/readyz initialDelaySeconds: 5 timeoutSeconds: 5 resources: limits: cpu: 1000m memory: 128Mi requests: cpu: 100m memory: 32Mi    Conditions     Read more on conditionsFor the quickstart we are going to add two conditions on top of the base condition called environment and location\nEnvironment     Now we want to add a condition, that podinfo is different names on different environments. The environment can be controlled via the values of the chart.\ncat \u0026lt;\u0026lt; EOF \u0026gt; ./helmize.yaml inventory_directory: \u0026#34;structure/\u0026#34; templates_directory: \u0026#34;tpls/\u0026#34; conditions: - name: \u0026#34;base\u0026#34; path: \u0026#34;/base/\u0026#34; allow_root: true - name: \u0026#34;environment\u0026#34; key: \u0026#34;Values.env\u0026#34; path: \u0026#34;env/\u0026#34; default: \u0026#34;test\u0026#34; filter: [ \u0026#34;test\u0026#34;, \u0026#34;prod\u0026#34; ] reverse_filter: true EOF Now we add two new structures for the environment testand prod\nTest Environment ...  Create Directory based on condition configuration\nmkdir -p structure/env/test/podinfo/ Create under the same path as in the base (podinfo/deploy.yaml) we want to merge over the file from the base. In thase case we adjust the name and the minReadySeconds properties.\ncat \u0026lt;\u0026lt; EOF \u0026gt; ./structure/env/test/podinfo/deploy.yaml apiVersion: apps/v1 kind: Deployment metadata: name: frontend-test spec: minReadySeconds: 10 EOF Create a HPA resource which should only be deployed on test\ncat \u0026lt;\u0026lt; EOF \u0026gt; ./structure/env/test/podinfo/hpa.yaml apiVersion: autoscaling/v2beta2 kind: HorizontalPodAutoscaler metadata: name: frontend spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: frontend-test minReplicas: 1 maxReplicas: 4 metrics: - type: Resource resource: name: cpu target: type: Utilization averageUtilization: 99 EOF Since we defined test as default for the environment we can template via\nhelm template . or with explicit value\nhelm template . --set \u0026#34;env=test\u0026#34; Both will result in the same output. Based on the output you can see that the hpa.yaml file is now rendered as well, but only if the environment is test. The Deployment files were also merged, since they both resolve into the subpath podinfo/deploy.yamlunderneath their condition folders.\nTest Environment ...  --- # Source: reference/templates/deploy.yaml # File: podinfo/service.yaml # Checksum 08b06c48a587e3fe6179875f70331bb97562a6e584dcb32807ce9eac7572fc8d apiVersion: v1 kind: Service metadata: name: frontend spec: ports: - name: http port: 80 protocol: TCP targetPort: http selector: app: frontend type: ClusterIP --- # File: podinfo/deploy.yaml # Checksum 30852c17c788e196ef62884c2e5bb092472a3b6b02d035bf39cdcbf6b54fc5e3 apiVersion: apps/v1 kind: Deployment metadata: name: frontend-test spec: minReadySeconds: 10 progressDeadlineSeconds: 60 revisionHistoryLimit: 5 selector: matchLabels: app: frontend strategy: rollingUpdate: maxUnavailable: 0 type: RollingUpdate template: metadata: annotations: prometheus.io/port: \u0026#34;9797\u0026#34; prometheus.io/scrape: \u0026#34;true\u0026#34; labels: app: frontend spec: containers: - command: - ./podinfo - --port=9898 - --port-metrics=9797 - --level=info - --backend-url=http://backend:9898/echo - --cache-server=cache:6379 env: - name: PODINFO_UI_COLOR value: \u0026#39;#34577c\u0026#39; image: ghcr.io/stefanprodan/podinfo:6.0.3 imagePullPolicy: IfNotPresent livenessProbe: exec: command: - podcli - check - http - localhost:9898/healthz initialDelaySeconds: 5 timeoutSeconds: 5 name: frontend ports: - containerPort: 9898 name: http protocol: TCP - containerPort: 9797 name: http-metrics protocol: TCP - containerPort: 9999 name: grpc protocol: TCP readinessProbe: exec: command: - podcli - check - http - localhost:9898/readyz initialDelaySeconds: 5 timeoutSeconds: 5 resources: limits: cpu: 1000m memory: 128Mi requests: cpu: 100m memory: 32Mi --- # Source: reference/templates/deploy.yaml # File: podinfo/hpa.yaml # Checksum 4669de4bb6631c64c7459e44b38c32a1236a0b7fb419b642d4a52b76ff51747c apiVersion: autoscaling/v2beta2 kind: HorizontalPodAutoscaler metadata: name: frontend spec: maxReplicas: 4 metrics: - resource: name: cpu target: averageUtilization: 99 type: Utilization type: Resource minReplicas: 1 scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: frontend      Prod Environment ...  Create Directory based on condition configuration\nmkdir -p structure/env/prod/podinfo/ Create under the same path as in the base (podinfo/deploy.yaml) we want to merge over the file from the base. In thase case we adjust the name and the minReadySeconds properties.\ncat \u0026lt;\u0026lt; EOF \u0026gt; ./structure/env/prod/podinfo/deploy.yaml apiVersion: apps/v1 kind: Deployment metadata: name: frontend-prod spec: minReadySeconds: 10 EOF For production we have to set the environment explicit\nhelm template . --set \u0026#34;env=prod\u0026#34; The Deployment files were also merged, since they both resolve into the subpath podinfo/deploy.yaml underneath their condition folders.\nProd Environment ...  --- # Source: reference/templates/deploy.yaml # File: podinfo/service.yaml # Checksum 08b06c48a587e3fe6179875f70331bb97562a6e584dcb32807ce9eac7572fc8d apiVersion: v1 kind: Service metadata: name: frontend spec: ports: - name: http port: 80 protocol: TCP targetPort: http selector: app: frontend type: ClusterIP --- # File: podinfo/deploy.yaml # Checksum f5f1922876fe509774c40afbd4576984bd3a952f248a3601a424966544a33892 apiVersion: apps/v1 kind: Deployment metadata: name: frontend-prod spec: minReadySeconds: 10 progressDeadlineSeconds: 60 revisionHistoryLimit: 5 selector: matchLabels: app: frontend strategy: rollingUpdate: maxUnavailable: 0 type: RollingUpdate template: metadata: annotations: prometheus.io/port: \u0026#34;9797\u0026#34; prometheus.io/scrape: \u0026#34;true\u0026#34; labels: app: frontend spec: containers: - command: - ./podinfo - --port=9898 - --port-metrics=9797 - --level=info - --backend-url=http://backend:9898/echo - --cache-server=cache:6379 env: - name: PODINFO_UI_COLOR value: \u0026#39;#34577c\u0026#39; image: ghcr.io/stefanprodan/podinfo:6.0.3 imagePullPolicy: IfNotPresent livenessProbe: exec: command: - podcli - check - http - localhost:9898/healthz initialDelaySeconds: 5 timeoutSeconds: 5 name: frontend ports: - containerPort: 9898 name: http protocol: TCP - containerPort: 9797 name: http-metrics protocol: TCP - containerPort: 9999 name: grpc protocol: TCP readinessProbe: exec: command: - podcli - check - http - localhost:9898/readyz initialDelaySeconds: 5 timeoutSeconds: 5 resources: limits: cpu: 1000m memory: 128Mi requests: cpu: 100m memory: 32Mi      As you can see the output changes based on the input of the chart.\nLocation     Let\u0026rsquo;s add a condition for the location. The location should also be controllable via Values of the chart.\ncat \u0026lt;\u0026lt; EOF \u0026gt; ./helmize.yaml inventory_directory: \u0026#34;structure/\u0026#34; templates_directory: \u0026#34;tpls/\u0026#34; conditions: - name: \u0026#34;base\u0026#34; path: \u0026#34;/base/\u0026#34; allow_root: true - name: \u0026#34;environment\u0026#34; key: \u0026#34;Values.env\u0026#34; path: \u0026#34;env/\u0026#34; default: \u0026#34;test\u0026#34; filter: [ \u0026#34;test\u0026#34;, \u0026#34;prod\u0026#34; ] reverse_filter: true - name: \u0026#34;location\u0026#34; key: \u0026#34;Values.location\u0026#34; EOF Now we add two new structures for the location east and west\nEast Environment ...  Create Directory based on condition configuration\nmkdir -p structure/location/east/podinfo/ Create under the same path as in the base (podinfo/deploy.yaml) we want to merge over the file from the base. We just add a location label to identify the deployment.\ncat \u0026lt;\u0026lt; EOF \u0026gt; ./structure/location/east/podinfo/deploy.yaml apiVersion: apps/v1 kind: Deployment metadata: labels location: \u0026#34;east\u0026#34; EOF There is on purpose an error in the above YAML to show you what happens in such a case  Now we can start combining two condiditions. So for now let\u0026rsquo;s select prod as environment and east as location\nhelm template . --set \u0026#34;env=prod\u0026#34; --set \u0026#34;location=east\u0026#34; There\u0026rsquo;s an error!\nTemplate Error ...  Error: execution error at (reference/templates/deploy.yaml:1:4): Found errors in render manifest, please resolve those errors or use the force options: - error: \u0026#39;error converting YAML to JSON: yaml: line 5: mapping values are not allowed in this context\u0026#39; file: structure/location/east/podinfo/deploy.yaml trace: | apiVersion: apps/v1 kind: Deployment metadata: labels location: \u0026#34;east\u0026#34;    Let\u0026rsquo;s fix this error\ncat \u0026lt;\u0026lt; EOF \u0026gt; ./structure/location/east/podinfo/deploy.yaml apiVersion: apps/v1 kind: Deployment metadata: labels: location: \u0026#34;east\u0026#34; EOF Now if we try the same template command again we get a result that looks much more like what we are looking for. As you can see we combined the two conditions prod and east. But we can do the exact same thing with every environment with every location, just by changing the values.\n  West Environment ...  Create Directory based on condition configuration\nmkdir -p structure/location/west/podinfo/ Create under the same path as in the base (podinfo/deploy.yaml) we want to merge over the file from the base. We just add a location label to identify the deployment.\ncat \u0026lt;\u0026lt; EOF \u0026gt; ./structure/location/west/podinfo/deploy.yaml apiVersion: apps/v1 kind: Deployment metadata: labels: location: \u0026#34;west\u0026#34; EOF Now we can start combining two condiditions. So for now let\u0026rsquo;s select test as environment and west as location\nhelm template . --set \u0026#34;env=test\u0026#34; --set \u0026#34;location=west\u0026#34; Now if we try the same template command again we get a result that looks much more like what we are looking for. As you can see we combined the two conditions test and west. But we can do the exact same thing with every environment with every location, just by changing the values.\nTest \u0026amp; West Environment ...  --- # Source: reference/templates/deploy.yaml # File: podinfo/service.yaml # Checksum 08b06c48a587e3fe6179875f70331bb97562a6e584dcb32807ce9eac7572fc8d apiVersion: v1 kind: Service metadata: name: frontend spec: ports: - name: http port: 80 protocol: TCP targetPort: http selector: app: frontend type: ClusterIP --- # File: podinfo/deploy.yaml # Checksum 3e8abeffd025ba5352bc97ab5cfb545902285dec8d27b6d1d46b8f44affd633b apiVersion: apps/v1 kind: Deployment metadata: labels: location: west name: frontend-test spec: minReadySeconds: 10 progressDeadlineSeconds: 60 revisionHistoryLimit: 5 selector: matchLabels: app: frontend strategy: rollingUpdate: maxUnavailable: 0 type: RollingUpdate template: metadata: annotations: prometheus.io/port: \u0026#34;9797\u0026#34; prometheus.io/scrape: \u0026#34;true\u0026#34; labels: app: frontend spec: containers: - command: - ./podinfo - --port=9898 - --port-metrics=9797 - --level=info - --backend-url=http://backend:9898/echo - --cache-server=cache:6379 env: - name: PODINFO_UI_COLOR value: \u0026#39;#34577c\u0026#39; image: ghcr.io/stefanprodan/podinfo:6.0.3 imagePullPolicy: IfNotPresent livenessProbe: exec: command: - podcli - check - http - localhost:9898/healthz initialDelaySeconds: 5 timeoutSeconds: 5 name: frontend ports: - containerPort: 9898 name: http protocol: TCP - containerPort: 9797 name: http-metrics protocol: TCP - containerPort: 9999 name: grpc protocol: TCP readinessProbe: exec: command: - podcli - check - http - localhost:9898/readyz initialDelaySeconds: 5 timeoutSeconds: 5 resources: limits: cpu: 1000m memory: 128Mi requests: cpu: 100m memory: 32Mi --- # Source: reference/templates/deploy.yaml # File: podinfo/hpa.yaml # Checksum 4669de4bb6631c64c7459e44b38c32a1236a0b7fb419b642d4a52b76ff51747c apiVersion: autoscaling/v2beta2 kind: HorizontalPodAutoscaler metadata: name: frontend spec: maxReplicas: 4 metrics: - resource: name: cpu target: averageUtilization: 99 type: Utilization type: Resource minReplicas: 1 scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: frontend      As seen with these two examples, conditions are a great mechanism to combine different indepdendent factors. You can extended the conditions at anytime without restructering the entire folder structure.\nDropins     Read more on dropinsWe create a simple that\u0026rsquo;s not really useful but helps you understand how dropins work:\ncat \u0026lt;\u0026lt; EOF \u0026gt;\u0026gt; ./helmize.yaml dropins: - patterns: [ \u0026#34;.*\u0026#34; ] data: labels: \u0026#34;custom.label\u0026#34;: \u0026#34;data\u0026#34; tpls: - \u0026#34;*.tpl\u0026#34; EOF This Dropin makes use of the Label Post Rendererand adds the registry.tpl\nregistry.tpl ...  First we have to create the templates directory we configured via templates_directory\nmkdir tpls/ Then Let\u0026rsquo;s add this Template under templates/registry.tpl\n{{/* Does not do much, but you can use templating to map values or use defaulting */}} {{- if $.Values.registry }} registry: {{ $.Values.registry }} {{- end }} {{/* Adds Another Label for the Post Renderer */}} labels: registy.template: \u0026quot;label\u0026quot; Since we include any files with the *.tpl ending in the templates directory this template will be used. If you want to be more explicit you would need to add only the registry.tpl\ncat \u0026lt;\u0026lt; EOF \u0026gt;\u0026gt; ./helmize.yaml dropins: - patterns: [ \u0026#34;.*\u0026#34; ] data: labels: \u0026#34;custom.label\u0026#34;: \u0026#34;data\u0026#34; tpls: - \u0026#34;registry.tpl\u0026#34; EOF In the structure/base/podinfo/deploy.yaml we change the image to default on the registry if it\u0026rsquo;s set, others use ghcr.io:\n... - name: frontend image: {{ default \u0026quot;ghcr.io\u0026quot; $.Data.registry }}/stefanprodan/podinfo:6.0.3 imagePullPolicy: IfNotPresent ... Now if we template with the registry set, we should see it\nhelm template . --set registry=\u0026quot;custom.registry\u0026quot; So we can access the results of dropings via the $.Data map in our file structure. Read More  Now have seen the basi principles helmize brings. It\u0026rsquo;s an help to organize large deployments and gives you greate customization which is value driven. The next step is to try it out for yourself! If there are still a lot of question marks, check out the exampleswhere we reference some implementations of helmize which might help you get started with your own use-case.\n"},{"id":14,"href":"/documentation/structure/","title":"Structure","parent":"Documentation","content":"    Files      Debug      Templating      "},{"id":15,"href":"/documentation/structure/templates/","title":"Templating","parent":"Structure","content":"Context     It\u0026rsquo;s important to know which context is available for templating at which stage.\nGlobal Context     As Global Context we refer to the value context delievered by helm. The below contexts may refer to thix context:\nDropin Context         "},{"id":16,"href":"/documentation/configuration/dropins/","title":"Dropins","parent":"Configuration","content":"Dropins are Values and templates which can be sustituted based on given path patterns. They allow greater customization through the use of sprig templates.\nConfiguration     Each dropin can have the followin configurations.\npatterns     Required\nType string/slice\nDefine regex patterns which match file paths you want to supply this dropin to.\ndata     Optional\nType map\nDefine data that will be available for the files that matched the pattern. You can not use sprig template here, the type must be map.\ntpls     Optional\nType string/slice\nTemplate locations to execute with thise dropin. Templates should be in dedicated files, otherwise they are very difficult to parse and hard to write for you as well. Therefor each value points to a template which is in a file. Each element can by a file or a path with template files in it.\nNOTE: The result of each template must be a valid dict, otherwise it\u0026rsquo;s considered an error.\nThe path is complementary to the templates_directorypath, if set.\n"},{"id":17,"href":"/documentation/post-renderers/","title":"Post Renderers","parent":"Documentation","content":"Post Renders allow the modification of your content after it has been combined over all conditions on a file basis. We don\u0026rsquo;t try to replicate posrenders which are already available for other tools.\n   Built-in      Labels        Extension      "},{"id":18,"href":"/guides/","title":"Guides","parent":"","content":"    Use with      Kustomization        "},{"id":19,"href":"/documentation/configuration/reference/","title":"Reference","parent":"Configuration","content":"Example configuration reference with documentation links.\n## Inventory Directory # http://helmize.dev/documentation/configuration/general/#inventory_directory inventory_directory: \u0026#34;groups/\u0026#34; ## Templates Directory # http://helmize.dev/documentation/configuration/general/#templates_directory templates_directory: \u0026#34;tpls/\u0026#34; ## Force # http://helmize.dev/documentation/configuration/general/#force force: false ## File Extensions # http://helmize.dev/documentation/configuration/general/#file_extensions file_extensions: [ \u0026#34;yaml\u0026#34; ] ## File Excludes # http://helmize.dev/documentation/configuration/general/#file_excludes file_excludes: [ \u0026#34;kustomization\u0026#34; ] ## Merge Strategy # http://helmize.dev/documentation/configuration/general/#merge_strategy merge_strategy: \u0026#34;path\u0026#34; ## Conditions # http://helmize.dev/documentation/configuration/conditions/ conditions: # Condition \u0026#34;Base\u0026#34; ## Name # http://helmize.dev/documentation/configuration/conditions/#name - name: \u0026#34;base\u0026#34; ## Path # http://helmize.dev/documentation/configuration/conditions/#path path: \u0026#34;/base/\u0026#34; ## Allow Root # http://helmize.dev/documentation/configuration/conditions/#allow_root allow_root: true # Condition \u0026#34;Environment\u0026#34; - name: \u0026#34;environment\u0026#34; ## Key # http://helmize.dev/documentation/configuration/conditions/#key key: \u0026#34;Values.config.environment\u0026#34; ## Key Types # http://helmize.dev/documentation/configuration/conditions/#key_types key_types: [ \u0026#34;string\u0026#34; ] ## Required # http://helmize.dev/documentation/configuration/conditions/#required  required: false ## Default # http://helmize.dev/documentation/configuration/conditions/#default  default: \u0026#34;default\u0026#34; ## Filter # http://helmize.dev/documentation/configuration/conditions/#filter  filter: [ \u0026#34;dev\u0026#34; ] ## Reverse Filter # http://helmize.dev/documentation/configuration/conditions/#reverse_filter reverse_filter: false ## Dropins # http://helmize.dev/documentation/configuration/dropins/ dropins: ## Patterns # http://helmize.dev/documentation/configuration/dropins/#patterns - patterns: [ \u0026#34;.*\u0026#34; ] ## Data  # http://helmize.dev/documentation/configuration/dropins/#data data: labels: \u0026#34;custom.label\u0026#34;: \u0026#34;data\u0026#34; ## Templates # http://helmize.dev/documentation/configuration/dropins/#tpls tpls: - \u0026#34;registry.tpl\u0026#34; "},{"id":20,"href":"/examples/","title":"Examples","parent":"","content":"We always welcome any examples, if you use helmize for your needs, consider adding it here (via Github Pull Request).\n"},{"id":21,"href":"/","title":"","parent":"","content":"This project is in the early stages of development and still activiely maintained. You may encounter behavior that\u0026rsquo;s not intended when making use of the project. If you find any bugs or have any questions feel free to open an issue (Click the Github Logo in the header)  Why     We have created this solution since there was nothing that would let us deploy complex structures based on values that change. We started of using Kustomizebut as soon as you have factors like environment, location, customer etc. you end up with huge large folder structures. These structures make hard to integrate with any other system you may have in your CI/CD cycle and is hard to keep control of. Das Schiffdid a great job with an example bootstrap structure in combination with Kustomize. But Kustomize does not deliver enough flexibility for such complex deployments. Another approach would be using kraanwhich allows such control over layers.\nBut the easiest solution to this is creating a helm chart yourself and place some yaml files in it and then based on values given to the chart render the yaml or not. That\u0026rsquo;s where helmize comes into play.\nHow     Helmize is just a simple chart library which simplifies creating complex infrastructure deployments within helm charts. Through the use of Helm you don\u0026rsquo;t need any additional operator or anything. It greatly integrates in any tool chain since you can customize it to your needs. It is complementary since it\u0026rsquo;s just advanced rendering in a helm chart, that means you can deploy any other crds or whatever you need (eg. kraan layers).\nRead MoreWho     This project is thought for people that bootstrap complex infrastructure setup on kubernetes and want the entire setup to be value driven. If you are looking for a simple solution for eg. a deployment for a single application this project might be too much overhead. If you have already experience with Helm it might be worth taking a look.\n"},{"id":22,"href":"/categories/","title":"Categories","parent":"","content":""},{"id":23,"href":"/tags/","title":"Tags","parent":"","content":""}]